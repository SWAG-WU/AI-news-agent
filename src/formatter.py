#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é£ä¹¦æ ¼å¼åŒ–æ¨¡å—

å°†èµ„è®¯æ ¼å¼åŒ–ä¸ºé£ä¹¦æœºå™¨äººå…¼å®¹çš„Markdownæ ¼å¼ï¼Œæ”¯æŒ6ç§åˆ†ç±»æ˜¾ç¤ºã€‚
"""

import logging
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from src.config import Config, get_config

logger = logging.getLogger(__name__)


class FeishuFormatter:
    """
    é£ä¹¦æ ¼å¼åŒ–å™¨

    å°†èµ„è®¯åˆ—è¡¨æ ¼å¼åŒ–ä¸ºé£ä¹¦æœºå™¨äººå…¼å®¹çš„Markdownæ—¥æŠ¥ï¼Œæ”¯æŒ6ç§åˆ†ç±»ï¼š
    1. å­¦æœ¯ç ”ç©¶ (academic)
    2. å®éªŒå®¤åšå®¢ (lab_blog)
    3. ä¸“ä¸šåª’ä½“ (media)
    4. å·¥å…·äº§å“ (tools)
    5. ç¤¾åŒºè®¨è®º (community)
    6. Newsletter (newsletter)
    """

    def __init__(self, config: Optional[Config] = None):
        self.config = config or get_config()
        self.prompts_dir = Path("prompts")

        # é»˜è®¤6ç§åˆ†ç±»æ˜ å°„ï¼ˆå¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼‰
        self.category_map = {
            "academic": "ğŸ“ å­¦æœ¯ç ”ç©¶",
            "lab_blog": "ğŸ¢ å®éªŒå®¤åšå®¢",
            "media": "ğŸ“° ä¸“ä¸šåª’ä½“",
            "tools": "ğŸ› ï¸ å·¥å…·äº§å“",
            "community": "ğŸ’¬ ç¤¾åŒºè®¨è®º",
            "newsletter": "ğŸ“§ Newsletter",
        }

        # åŠ è½½è‡ªå®šä¹‰åˆ†ç±»é…ç½®
        self._load_category_config()

        # åŠ è½½æç¤ºè¯æ¨¡æ¿
        self._prompt_template = self._load_prompt_template()

    def _load_category_config(self):
        """åŠ è½½åˆ†ç±»é…ç½®"""
        if self.config.categories:
            for cat_id, cat_info in self.config.categories.categories.items():
                self.category_map[cat_id] = f"{cat_info.icon} {cat_info.name}"

    def _load_prompt_template(self) -> str:
        """åŠ è½½æ—¥æŠ¥ç”Ÿæˆæç¤ºè¯æ¨¡æ¿"""
        prompt_path = self.prompts_dir / "daily_report.txt"

        if prompt_path.exists():
            with open(prompt_path, "r", encoding="utf-8") as f:
                return f.read()

        return None

    async def format(self, articles: List[Dict[str, Any]]) -> str:
        """
        æ ¼å¼åŒ–èµ„è®¯ä¸ºé£ä¹¦æ—¥æŠ¥

        Args:
            articles: èµ„è®¯åˆ—è¡¨

        Returns:
            æ ¼å¼åŒ–åçš„Markdownæ–‡æœ¬
        """
        logger.info(f"å¼€å§‹æ ¼å¼åŒ–æ—¥æŠ¥ï¼Œæ–‡ç« æ•°: {len(articles)}")

        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿå†…å®¹
        min_items = self.config.thresholds.daily_output.min_total_items

        if len(articles) < min_items:
            logger.warning(f"èµ„è®¯æ•°é‡ä¸è¶³ ({len(articles)} < {min_items})ï¼Œä½¿ç”¨å›é€€æ ¼å¼")
            return self._format_fallback(articles)

        # åˆ†ç¦»å¸¸è§„èµ„è®¯å’Œé¢å¤–èµ„è®¯ï¼ˆæ–°æ¨¡å‹å‘å¸ƒç­‰ï¼‰
        regular_articles = []
        extra_articles = []

        for article in articles:
            if article.get('is_extra', False):
                extra_articles.append(article)
            else:
                regular_articles.append(article)

        logger.info(f"å¸¸è§„èµ„è®¯: {len(regular_articles)} æ¡, é¢å¤–èµ„è®¯: {len(extra_articles)} æ¡")

        # æŒ‰åˆ†ç±»æ•´ç†èµ„è®¯
        categorized = self._categorize_articles(regular_articles)

        # ç”Ÿæˆæ—¥æŠ¥
        report = self._generate_report(categorized, extra_articles)

        logger.info("æ—¥æŠ¥æ ¼å¼åŒ–å®Œæˆ")
        return report

    def _categorize_articles(self, articles: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """
        å°†æ–‡ç« æŒ‰6ç§åˆ†ç±»æ•´ç†ï¼Œå¹¶æŒ‰å‘å¸ƒæ—¶é—´é™åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰

        åˆ†ç±»ä¼˜å…ˆçº§ï¼š
        1. å¦‚æœæ–‡ç« å·²æœ‰ category å­—æ®µï¼Œä½¿ç”¨è¯¥åˆ†ç±»
        2. å¦åˆ™æ ¹æ® source å­—æ®µæ˜ å°„åˆ°åˆ†ç±»
        3. æœ€åæ ¹æ®å…³é”®è¯å†…å®¹æ¨æ–­åˆ†ç±»
        """
        categorized = {
            "academic": [],
            "lab_blog": [],
            "media": [],
            "tools": [],
            "community": [],
            "newsletter": [],
        }

        for article in articles:
            category = self._determine_category(article)

            if category in categorized:
                categorized[category].append(article)
            else:
                # é»˜è®¤å½’å…¥å­¦æœ¯ç ”ç©¶
                categorized["academic"].append(article)

        # æŒ‰å‘å¸ƒæ—¶é—´é™åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰ï¼Œpublished_at ä¸ºç©ºçš„æ’åœ¨æœ€å
        for category_key in categorized:
            categorized[category_key].sort(
                key=lambda x: x.get("published_at") or "1970-01-01T00:00:00Z",
                reverse=True
            )

        return categorized

    def _determine_category(self, article: Dict[str, Any]) -> str:
        """
        ç¡®å®šæ–‡ç« çš„åˆ†ç±»

        ä¼˜å…ˆçº§ï¼š
        1. æ–‡ç« å·²æœ‰çš„ category å­—æ®µ
        2. æ ¹æ® source å­—æ®µæ˜ å°„
        3. æ ¹æ®å…³é”®è¯å†…å®¹æ¨æ–­
        """
        # 1. æ£€æŸ¥æ–‡ç« æ˜¯å¦å·²æœ‰åˆ†ç±»
        if "category" in article and article["category"] in self.category_map:
            return article["category"]

        # 2. æ ¹æ® source æ˜ å°„
        source = article.get("source", "").lower()
        if self.config.categories:
            mapped = self.config.categories.map_source_to_category(source)
            if mapped:
                return mapped

        # 3. æ ¹æ®å…³é”®è¯å†…å®¹æ¨æ–­
        title = article.get("title", "").lower()
        description = article.get("description", "").lower()
        text = f"{title} {description}"

        if self.config.categories:
            inferred = self.config.categories.get_category_by_keywords(text)
            if inferred:
                return inferred

        # 4. é»˜è®¤åˆ†ç±»æ¨æ–­
        if any(kw in text for kw in ["arxiv", "paper", "research", "neurips", "icml"]):
            return "academic"
        elif any(kw in text for kw in ["openai", "deepmind", "anthropic", "google", "meta", "blog"]):
            return "lab_blog"
        elif any(kw in text for kw in ["product hunt", "tool", "app", "platform", "release"]):
            return "tools"
        elif any(kw in text for kw in ["hacker news", "reddit", "discussion"]):
            return "community"
        elif any(kw in text for kw in ["newsletter", "batch", "import ai"]):
            return "newsletter"
        else:
            return "media"

    def _generate_report(self, categorized: Dict[str, List[Dict[str, Any]]], extra_articles: List[Dict[str, Any]] = None) -> str:
        """ç”Ÿæˆæ—¥æŠ¥æ–‡æœ¬"""
        lines = []

        # æ ‡é¢˜
        date_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        lines.append(f"# ã€AIå‰æ²¿æ—¥æŠ¥ï½œ{date_str}ã€‘")
        lines.append("")

        # ç»Ÿè®¡ä¿¡æ¯
        total_count = sum(len(articles) for articles in categorized.values())
        extra_count = len(extra_articles) if extra_articles else 0
        lines.append(f"ğŸ“Š ä»Šæ—¥å…±æ”¶å½• {total_count} æ¡èµ„è®¯" + (f" + {extra_count} æ¡ç‰¹åˆ«èµ„è®¯" if extra_count > 0 else ""))
        lines.append("")

        # ========== æ–°æ¨¡å‹å‘å¸ƒç‰¹åˆ«èµ„è®¯ï¼ˆå¦‚æœæœ‰ï¼‰==========
        if extra_articles and extra_count > 0:
            lines.append("## ğŸš€ ç‰¹åˆ«å…³æ³¨ï¼šæ–°æ¨¡å‹å‘å¸ƒ")
            lines.append("")

            # æŒ‰æ–°æ¨¡å‹ç±»å‹åˆ†ç»„
            new_model_articles = [a for a in extra_articles if a.get('extra_type') == 'new_model_release']

            if new_model_articles:
                lines.append("*æ£€æµ‹åˆ°é‡è¦æ¨¡å‹å‘å¸ƒï¼Œçªç ´å¸¸è§„èµ„è®¯é™åˆ¶*")
                lines.append("")

                for article in new_model_articles:
                    model_info = article.get('model_info', {})
                    model_name = model_info.get('model_name', 'æ–°æ¨¡å‹')
                    company = model_info.get('company', '')

                    title = article.get("title", "").strip()
                    summary = article.get("summary", article.get("description", "")).strip()
                    url = article.get("url", "")
                    source = article.get("source", "")
                    published_at = article.get("published_at", "")

                    # æ ¼å¼åŒ–æ—¶é—´
                    formatted_time = self._format_published_time(published_at)

                    # æ ¼å¼åŒ–æ–°æ¨¡å‹å‘å¸ƒèµ„è®¯
                    lines.append(f"### {model_name}")
                    if company:
                        lines.append(f"*{company}*")
                    if formatted_time:
                        lines.append(f"*ğŸ•’ {formatted_time}*")
                    lines.append("")
                    lines.append(summary[:300])
                    if url:
                        lines.append(f"[æŸ¥çœ‹è¯¦æƒ…]({url})")
                    lines.append("")

            lines.append("---")
            lines.append("")

        # ========== å¸¸è§„èµ„è®¯ ==========
        # æŒ‰åˆ†ç±»ä¼˜å…ˆçº§é¡ºåºç”Ÿæˆå†…å®¹
        category_order = ["academic", "lab_blog", "media", "tools", "community", "newsletter"]

        for category_key in category_order:
            articles = categorized.get(category_key, [])

            if not articles:
                continue  # ç©ºåˆ†ç±»ä¸æ˜¾ç¤º

            category_label = self.category_map.get(category_key, category_key)

            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§æ•°é‡
            max_items = self.config.thresholds.daily_output.max_items_per_category.get(
                category_key, 10
            )

            lines.append(f"## {category_label}")
            lines.append("")

            for article in articles[:max_items]:
                lines.append(self._format_article(article, category_key))
                lines.append("")

        # é¡µè„š
        lines.append("---")
        lines.append(f"âœ… æ•°æ®æˆªè‡³ {date_str} | æ¥æºï¼šarXiv / å®˜æ–¹åšå®¢ / ä¸“ä¸šåª’ä½“ / ç¤¾åŒºç­‰")

        return "\n".join(lines)

    def _format_article(self, article: Dict[str, Any], category: str) -> str:
        """æ ¼å¼åŒ–å•ç¯‡æ–‡ç« """
        title = article.get("title", "").strip()
        summary = article.get("summary", article.get("description", "")).strip()
        url = article.get("url", "")
        source = article.get("source", "")
        author = article.get("author", "")
        institution = article.get("institution", "")
        published_at = article.get("published_at", "")

        # æ ¼å¼åŒ–å‘å¸ƒæ—¶é—´
        formatted_time = self._format_published_time(published_at)

        # æ ¹æ®åˆ†ç±»ä½¿ç”¨ä¸åŒæ ¼å¼
        if category == "academic":
            return self._format_academic_article(title, summary, author, institution, url, formatted_time)
        elif category == "lab_blog":
            return self._format_lab_blog_article(title, summary, source, url, formatted_time)
        elif category == "media":
            return self._format_media_article(title, summary, source, url, formatted_time)
        elif category == "tools":
            return self._format_tools_article(title, summary, url, formatted_time)
        elif category == "community":
            return self._format_community_article(title, summary, source, url, formatted_time)
        elif category == "newsletter":
            return self._format_newsletter_article(title, summary, source, url, formatted_time)
        else:
            return self._format_default_article(title, summary, url, formatted_time)

    def _format_published_time(self, published_at: str) -> str:
        """æ ¼å¼åŒ–å‘å¸ƒæ—¶é—´ä¸ºä¸­æ–‡å‹å¥½æ ¼å¼"""
        if not published_at:
            return ""

        try:
            # å°è¯•è§£æ ISO æ ¼å¼æ—¶é—´
            for fmt in ["%Y-%m-%dT%H:%M:%SZ", "%Y-%m-%dT%H:%M:%S.%fZ",
                       "%Y-%m-%dT%H:%M:%S%z", "%Y-%m-%dT%H:%M:%S"]:
                try:
                    dt = datetime.strptime(published_at.replace("Z", ""), "%Y-%m-%dT%H:%M:%S")
                    # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´ (UTC+8)
                    from datetime import timedelta
                    dt_beijing = dt + timedelta(hours=8)
                    return dt_beijing.strftime("%mæœˆ%dæ—¥ %H:%M")
                except ValueError:
                    continue
            return published_at
        except Exception:
            return published_at

    def _infer_source_from_url(self, url: str) -> str:
        """æ ¹æ® URL æ¨æ–­æ¥æºå¹³å°"""
        if not url:
            return ""

        url_lower = url.lower()

        # GitHub
        if "github.com" in url_lower or "github.io" in url_lower:
            return "GitHub"

        # OpenAI
        if "openai.com" in url_lower:
            return "OpenAI"

        # Microsoft
        if "microsoft.com" in url_lower or "microsoftresearch" in url_lower:
            return "Microsoft"

        # Google
        if "google.com" in url_lower or "googleblog" in url_lower:
            return "Google"

        # Meta
        if "meta.com" in url_lower or "fb.com" in url_lower:
            return "Meta"

        # Anthropic
        if "anthropic.com" in url_lower:
            return "Anthropic"

        # arXiv
        if "arxiv.org" in url_lower:
            return "arXiv"

        # Hugging Face
        if "huggingface.co" in url_lower:
            return "Hugging Face"

        # MIT Technology Review
        if "technologyreview.com" in url_lower:
            return "MIT Tech Review"

        # The Verge
        if "theverge.com" in url_lower:
            return "The Verge"

        # Wired
        if "wired.com" in url_lower:
            return "Wired"

        # Nature
        if "nature.com" in url_lower:
            return "Nature"

        # Wired
        if "wired.com" in url_lower:
            return "Wired"

        # é€šç”¨åŸŸåæå–
        import re
        match = re.search(r'(?:https?://)?(?:www\.)?([a-zA-Z0-9-]+)\.(?:com|org|io|net|ai)', url_lower)
        if match:
            domain = match.group(1)
            # ç®€å•é¦–å­—æ¯å¤§å†™
            return domain.capitalize()

        return ""

    def _format_academic_article(self, title: str, summary: str,
                                author: str, institution: str, url: str,
                                formatted_time: str = "") -> str:
        """æ ¼å¼åŒ–å­¦æœ¯ç ”ç©¶æ–‡ç« """
        lines = []
        lines.append(f"### {title}")

        # æ·»åŠ ä½œè€…/æœºæ„ä¿¡æ¯
        meta_info = []
        if author:
            meta_info.append(f"ä½œè€…: {author}")
        if institution:
            meta_info.append(f"æœºæ„: {institution}")
        if formatted_time:
            meta_info.append(f"ğŸ•’ {formatted_time}")

        if meta_info:
            lines.append("*" + " | ".join(meta_info) + "*")

        lines.append("")
        lines.append(summary[:300])
        if url:
            lines.append(f"[æŸ¥çœ‹è®ºæ–‡]({url})")

        return "\n".join(lines)

    def _format_lab_blog_article(self, title: str, summary: str,
                                 source: str, url: str,
                                 formatted_time: str = "") -> str:
        """æ ¼å¼åŒ–å®éªŒå®¤åšå®¢æ–‡ç« """
        lines = []
        lines.append(f"### {title}")

        meta_info = []
        if source:
            meta_info.append(f"æ¥æº: {source}")
        if formatted_time:
            meta_info.append(f"ğŸ•’ {formatted_time}")

        if meta_info:
            lines.append("*" + " | ".join(meta_info) + "*")

        lines.append("")
        lines.append(summary[:300])
        if url:
            lines.append(f"[é˜…è¯»åŸæ–‡]({url})")

        return "\n".join(lines)

    def _format_media_article(self, title: str, summary: str,
                             source: str, url: str,
                             formatted_time: str = "") -> str:
        """æ ¼å¼åŒ–ä¸“ä¸šåª’ä½“æ–‡ç« """
        lines = []
        lines.append(f"### {title}")

        meta_info = []
        if source:
            meta_info.append(f"{source}")
        if formatted_time:
            meta_info.append(f"ğŸ•’ {formatted_time}")

        if meta_info:
            lines.append("*" + " | ".join(meta_info) + "*")

        lines.append("")
        lines.append(summary[:300])
        if url:
            lines.append(f"[é˜…è¯»å…¨æ–‡]({url})")

        return "\n".join(lines)

    def _format_tools_article(self, title: str, summary: str,
                             url: str,
                             formatted_time: str = "") -> str:
        """æ ¼å¼åŒ–å·¥å…·äº§å“æ–‡ç« """
        lines = []
        lines.append(f"### {title}")

        if formatted_time:
            lines.append(f"*ğŸ•’ {formatted_time}*")

        lines.append("")
        lines.append(summary[:300])
        if url:
            lines.append(f"[æŸ¥çœ‹äº§å“]({url})")

        return "\n".join(lines)

    def _format_community_article(self, title: str, summary: str,
                                  source: str, url: str,
                                  formatted_time: str = "") -> str:
        """æ ¼å¼åŒ–ç¤¾åŒºè®¨è®ºæ–‡ç« """
        lines = []
        lines.append(f"### {title}")

        meta_info = []
        if source:
            meta_info.append(f"æ¥æº: {source}")
        if formatted_time:
            meta_info.append(f"ğŸ•’ {formatted_time}")

        if meta_info:
            lines.append("*" + " | ".join(meta_info) + "*")

        lines.append("")
        lines.append(summary[:300])
        if url:
            lines.append(f"[å‚ä¸è®¨è®º]({url})")

        return "\n".join(lines)

    def _format_newsletter_article(self, title: str, summary: str,
                                   source: str, url: str,
                                   formatted_time: str = "") -> str:
        """æ ¼å¼åŒ–Newsletteræ–‡ç« """
        lines = []
        lines.append(f"### {title}")

        meta_info = []
        if source:
            meta_info.append(f"æ¥æº: {source}")
        if formatted_time:
            meta_info.append(f"ğŸ•’ {formatted_time}")

        if meta_info:
            lines.append("*" + " | ".join(meta_info) + "*")

        lines.append("")
        lines.append(summary[:300])
        if url:
            lines.append(f"[é˜…è¯»åŸæ–‡]({url})")

        return "\n".join(lines)

    def _format_default_article(self, title: str, summary: str, url: str,
                               formatted_time: str = "") -> str:
        """é»˜è®¤æ ¼å¼"""
        lines = []
        lines.append(f"### {title}")

        if formatted_time:
            lines.append(f"*ğŸ•’ {formatted_time}*")

        lines.append("")
        lines.append(summary[:300])
        if url:
            lines.append(f"[æŸ¥çœ‹è¯¦æƒ…]({url})")

        return "\n".join(lines)

    def _format_fallback(self, articles: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–å›é€€ç‰ˆæœ¬ï¼ˆèµ„è®¯ä¸è¶³æ—¶ï¼‰"""
        date_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")

        lines = []
        lines.append(f"# ã€AIå‰æ²¿æ—¥æŠ¥ï½œ{date_str}ã€‘")
        lines.append("")

        if not articles:
            lines.append("ğŸŸ¡ å½“å‰æ—¶æ®µæš‚æ— é‡å¤§AIæ›´æ–°ã€‚")
            lines.append("")
            lines.append("å»ºè®®æŒç»­å…³æ³¨ arXiv CS.AI ä¸ HuggingFace æ–°åŠ¨å‘ã€‚")
        else:
            lines.append("ğŸŸ¡ å½“å‰æ—¶æ®µé‡å¤§æ›´æ–°è¾ƒå°‘ï¼Œä»¥ä¸‹æ˜¯ä¸ºæ‚¨æ•´ç†çš„èµ„è®¯ï¼š")
            lines.append("")

            for article in articles:
                title = article.get('title', '')
                summary = article.get("summary", article.get("description", ""))
                url = article.get('url', '')
                source = article.get('source', '')

                lines.append(f"## {title}")
                if summary:
                    lines.append(summary[:200])
                # æ·»åŠ æ¥æºå’Œé“¾æ¥
                if source:
                    lines.append(f"*æ¥æº: {source}*")
                if url:
                    lines.append(f"[æŸ¥çœ‹è¯¦æƒ…]({url})")
                lines.append("")

        lines.append("---")
        lines.append(f"âœ… æ•°æ®æˆªè‡³ {date_str} | æ¥æºï¼šarXiv / å®˜æ–¹åšå®¢ / ä¸“ä¸šåª’ä½“ / ç¤¾åŒºç­‰")

        return "\n".join(lines)


class FeishuCardFormatter(FeishuFormatter):
    """
    é£ä¹¦å¡ç‰‡æ ¼å¼åŒ–å™¨

    ç”Ÿæˆç»“æ„åŒ–é£ä¹¦å¡ç‰‡æ¶ˆæ¯ï¼Œä½¿ç”¨å¤šå…ƒç´ å¸ƒå±€æ›¿ä»£çº¯æ–‡æœ¬ Markdownã€‚
    """

    _LINK_LABELS = {
        "academic": "æŸ¥çœ‹è®ºæ–‡",
        "lab_blog": "é˜…è¯»åŸæ–‡",
        "media": "é˜…è¯»å…¨æ–‡",
        "tools": "æŸ¥çœ‹äº§å“",
        "community": "å‚ä¸è®¨è®º",
        "newsletter": "é˜…è¯»åŸæ–‡",
        "extra": "æŸ¥çœ‹è¯¦æƒ…",
    }

    async def format(self, articles: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ ¼å¼åŒ–ä¸ºé£ä¹¦ç»“æ„åŒ–å¡ç‰‡

        Returns:
            é£ä¹¦å¡ç‰‡æ¶ˆæ¯å­—å…¸
        """
        date_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        min_items = self.config.thresholds.daily_output.min_total_items

        if len(articles) < min_items:
            return self._build_fallback_card(articles, date_str)

        regular_articles = [a for a in articles if not a.get("is_extra", False)]
        extra_articles = [a for a in articles if a.get("is_extra", False)]
        categorized = self._categorize_articles(regular_articles)

        total_count = sum(len(v) for v in categorized.values())
        extra_count = len(extra_articles)

        elements = []

        # ç»Ÿè®¡æ‘˜è¦è¡Œ
        summary_text = f"ğŸ“Š ä»Šæ—¥å…±æ”¶å½• **{total_count}** æ¡èµ„è®¯"
        if extra_count > 0:
            summary_text += f" + **{extra_count}** æ¡ç‰¹åˆ«èµ„è®¯"
        elements.append({"tag": "div", "text": {"tag": "lark_md", "content": summary_text}})

        # æ–°æ¨¡å‹å‘å¸ƒç‰¹åˆ«èµ„è®¯
        if extra_articles:
            elements.append({"tag": "hr"})
            # ä½¿ç”¨å¼•ç”¨æ ·å¼çªå‡ºç‰¹åˆ«èµ„è®¯æ ‡é¢˜
            elements.append({
                "tag": "div",
                "text": {"tag": "lark_md", "content": "> ğŸš€ **ç‰¹åˆ«å…³æ³¨ï¼šæ–°æ¨¡å‹å‘å¸ƒ**\n*> æ£€æµ‹åˆ°é‡è¦æ¨¡å‹å‘å¸ƒï¼Œçªç ´å¸¸è§„èµ„è®¯é™åˆ¶*"}
            })
            for i, article in enumerate(extra_articles):
                elements.append({"tag": "div", "text": {"tag": "lark_md", "content": self._article_to_lark_md(article, "extra")}})
                if i < len(extra_articles) - 1:
                    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "---"}})

        # å¸¸è§„åˆ†ç±»
        category_order = ["academic", "lab_blog", "media", "tools", "community", "newsletter"]
        for cat_key in category_order:
            arts = categorized.get(cat_key, [])
            if not arts:
                continue
            max_items = self.config.thresholds.daily_output.max_items_per_category.get(cat_key, 10)
            label = self.category_map.get(cat_key, cat_key)

            elements.append({"tag": "hr"})
            # ä½¿ç”¨å¼•ç”¨æ ·å¼çªå‡ºåˆ†ç±»æ ‡é¢˜ï¼Œå¢å¼ºè§†è§‰å±‚çº§
            elements.append({"tag": "div", "text": {"tag": "lark_md", "content": f"> **{label}**"}})
            for i, article in enumerate(arts[:max_items]):
                elements.append({"tag": "div", "text": {"tag": "lark_md", "content": self._article_to_lark_md(article, cat_key)}})
                # éæœ€åä¸€æ¡æ–‡ç« åæ·»åŠ åˆ†éš”çº¿
                if i < len(arts[:max_items]) - 1:
                    elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "---"}})

        # é¡µè„š
        elements.append({"tag": "hr"})
        elements.append({"tag": "div", "text": {"tag": "lark_md", "content": f"âœ… æ•°æ®æˆªè‡³ {date_str} | æ¥æºï¼šarXiv / å®˜æ–¹åšå®¢ / ä¸“ä¸šåª’ä½“ / ç¤¾åŒºç­‰"}})

        return {
            "msg_type": "interactive",
            "card": {
                "header": {
                    "title": {"tag": "plain_text", "content": f"ğŸ“¡ AIå‰æ²¿æ—¥æŠ¥ | {date_str}"},
                    "template": "blue"
                },
                "elements": elements
            }
        }

    def _article_to_lark_md(self, article: Dict[str, Any], category: str) -> str:
        """å°†æ–‡ç« è½¬æ¢ä¸º lark_md æ ¼å¼å­—ç¬¦ä¸²ï¼Œå¢å¼ºè§†è§‰å±‚çº§"""
        title = article.get("title", "").strip()
        summary = article.get("summary", article.get("description", "")).strip()
        url = article.get("url", "")
        source = article.get("source", "")
        author = article.get("author", "")
        institution = article.get("institution", "")
        published_at = article.get("published_at", "")
        formatted_time = self._format_published_time(published_at)

        lines = [f"**â–¸ {title}**"]

        # å…ƒä¿¡æ¯è¡Œ
        meta_parts = []
        if category == "academic":
            if author:
                meta_parts.append(f"ğŸ‘¤ {author}")
            if institution:
                meta_parts.append(f"ğŸ›ï¸ {institution}")
            # å­¦æœ¯ç ”ç©¶ä¹Ÿæ˜¾ç¤ºæ¥æºå¹³å°
            if source:
                meta_parts.append(f"ğŸ“¢ {source}")
            else:
                inferred_source = self._infer_source_from_url(url)
                if inferred_source:
                    meta_parts.append(f"ğŸ“¢ {inferred_source}")
        elif category == "extra":
            model_info = article.get("model_info", {})
            company = model_info.get("company", "")
            if company:
                meta_parts.append(f"ğŸ¢ {company}")
            # æ ¹æ® URL æ¨æ–­æ¥æº
            inferred_source = self._infer_source_from_url(url)
            if inferred_source:
                meta_parts.append(f"ğŸ“¢ {inferred_source}")
        else:
            # ä¼˜å…ˆä½¿ç”¨ sourceï¼Œå¦‚æœä¸ºç©ºåˆ™æ ¹æ® URL æ¨æ–­
            if source:
                meta_parts.append(f"ğŸ“¢ {source}")
            else:
                # æ ¹æ® URL æ¨æ–­æ¥æºå¹³å°
                inferred_source = self._infer_source_from_url(url)
                if inferred_source:
                    meta_parts.append(f"ğŸ“¢ {inferred_source}")
        if formatted_time:
            meta_parts.append(f"ğŸ•’ {formatted_time}")

        if meta_parts:
            lines.append("`" + " â”‚ ".join(meta_parts) + "`")

        if summary:
            lines.append(f"> {summary[:280]}")

        if url:
            label = self._LINK_LABELS.get(category, "æŸ¥çœ‹è¯¦æƒ…")
            lines.append(f"ğŸ‘‰ [{label}]({url})")

        return "\n".join(lines)

    def _build_fallback_card(self, articles: List[Dict[str, Any]], date_str: str) -> Dict[str, Any]:
        """èµ„è®¯ä¸è¶³æ—¶çš„å›é€€å¡ç‰‡"""
        elements = []

        if not articles:
            elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "ğŸŸ¡ å½“å‰æ—¶æ®µæš‚æ— é‡å¤§AIæ›´æ–°ã€‚\n\nå»ºè®®æŒç»­å…³æ³¨ arXiv CS.AI ä¸ HuggingFace æ–°åŠ¨å‘ã€‚"}})
        else:
            elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "ğŸŸ¡ å½“å‰æ—¶æ®µé‡å¤§æ›´æ–°è¾ƒå°‘ï¼Œä»¥ä¸‹æ˜¯ä¸ºæ‚¨æ•´ç†çš„èµ„è®¯ï¼š"}})
            for article in articles:
                title = article.get("title", "")
                summary = article.get("summary", article.get("description", ""))
                url = article.get("url", "")
                source = article.get("source", "")

                lines = [f"**{title}**"]
                if summary:
                    lines.append(summary[:200])
                if source:
                    lines.append(f"*æ¥æº: {source}*")
                if url:
                    lines.append(f"[æŸ¥çœ‹è¯¦æƒ…]({url})")
                elements.append({"tag": "div", "text": {"tag": "lark_md", "content": "\n".join(lines)}})

        elements.append({"tag": "hr"})
        elements.append({"tag": "div", "text": {"tag": "lark_md", "content": f"âœ… æ•°æ®æˆªè‡³ {date_str} | æ¥æºï¼šarXiv / å®˜æ–¹åšå®¢ / ä¸“ä¸šåª’ä½“ / ç¤¾åŒºç­‰"}})

        return {
            "msg_type": "interactive",
            "card": {
                "header": {
                    "title": {"tag": "plain_text", "content": f"ğŸ“¡ AIå‰æ²¿æ—¥æŠ¥ | {date_str}"},
                    "template": "blue"
                },
                "elements": elements
            }
        }
