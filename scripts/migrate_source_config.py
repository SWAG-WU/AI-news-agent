#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¿¡æ¯æºé…ç½®è¿ç§»è„šæœ¬

å°†æ—§çš„é…ç½®æ ¼å¼è¿ç§»åˆ°æ–°çš„ç»Ÿä¸€é…ç½®æ ¼å¼ã€‚
"""

import json
import shutil
import sys
from pathlib import Path
from datetime import datetime
from typing import Any, Dict


# è®¾ç½®æ§åˆ¶å°è¾“å‡ºç¼–ç ä¸º UTF-8
if sys.platform == "win32":
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')


class SourceConfigMigrator:
    """ä¿¡æ¯æºé…ç½®è¿ç§»å™¨"""

    def __init__(self, config_dir: str = "config"):
        self.config_dir = Path(config_dir)
        self.sources_file = self.config_dir / "sources.json"
        self.backup_file = self.config_dir / f"sources.json.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"

    def migrate(self) -> bool:
        """æ‰§è¡Œè¿ç§»"""
        print("=" * 60)
        print("ä¿¡æ¯æºé…ç½®è¿ç§»å·¥å…·")
        print("=" * 60)
        print()

        # 1. å¤‡ä»½åŸé…ç½®
        print(f"ğŸ“¦ å¤‡ä»½åŸé…ç½®åˆ°: {self.backup_file.name}")
        shutil.copy2(self.sources_file, self.backup_file)
        print("âœ… å¤‡ä»½å®Œæˆ")
        print()

        # 2. è¯»å–åŸé…ç½®
        print(f"ğŸ“– è¯»å–é…ç½®æ–‡ä»¶: {self.sources_file}")
        with open(self.sources_file, "r", encoding="utf-8") as f:
            old_data = json.load(f)

        old_sources = old_data.get("sources", [])
        fallback_sources = old_data.get("fallback_sources", [])

        print(f"   æ‰¾åˆ° {len(old_sources)} ä¸ªä¸»ä¿¡æ¯æº")
        print(f"   æ‰¾åˆ° {len(fallback_sources)} ä¸ªå¤‡ç”¨ä¿¡æ¯æº")
        print()

        # 3. è½¬æ¢é…ç½®
        print("ğŸ”„ å¼€å§‹è½¬æ¢é…ç½®...")
        new_sources = []
        for source in old_sources:
            new_source = self._convert_source(source)
            new_sources.append(new_source)

        # è½¬æ¢ fallback_sources
        new_fallback = []
        for source in fallback_sources:
            new_source = self._convert_source(source)
            new_fallback.append(new_source)

        print(f"âœ… è½¬æ¢äº† {len(new_sources)} ä¸ªä¸»ä¿¡æ¯æº")
        print(f"âœ… è½¬æ¢äº† {len(new_fallback)} ä¸ªå¤‡ç”¨ä¿¡æ¯æº")
        print()

        # 4. æ„å»ºæ–°é…ç½®
        new_config = {
            "$schema": "./schemas/source.schema.json",
            "title": "AIèµ„è®¯ä¿¡æ¯æºé…ç½®",
            "description": "ç»Ÿä¸€æ ¼å¼é…ç½® - ç”±è¿ç§»å·¥å…·è‡ªåŠ¨ç”Ÿæˆ",
            "sources": new_sources,
            "fallback_sources": new_fallback,
            "global_settings": {
                "default_rate_limit": {
                    "requests_per_minute": 10,
                    "burst_size": 5
                },
                "default_cache": {
                    "enabled": True,
                    "ttl_minutes": 60,
                    "strategy": "memory"
                },
                "timeout": {
                    "connect": 10,
                    "read": 30
                }
            },
            "categories": {
                "academic": {"max_items_per_day": 20, "min_score": 0.6},
                "lab_blog": {"max_items_per_day": 15, "min_score": 0.5},
                "media": {"max_items_per_day": 30, "min_score": 0.4},
                "tools": {"max_items_per_day": 25, "min_score": 0.3},
                "community": {"max_items_per_day": 10, "min_score": 0.7},
                "newsletter": {"max_items_per_day": 5, "min_score": 0.5}
            }
        }

        # 5. å†™å…¥æ–°é…ç½®
        print(f"ğŸ’¾ å†™å…¥æ–°é…ç½®åˆ°: {self.sources_file}")
        with open(self.sources_file, "w", encoding="utf-8") as f:
            json.dump(new_config, f, ensure_ascii=False, indent=2)

        print("âœ… è¿ç§»å®Œæˆï¼")
        print()

        # 6. æ˜¾ç¤ºç»Ÿè®¡
        self._show_statistics(new_sources + new_fallback)

        print()
        print("ğŸ“ æ³¨æ„äº‹é¡¹ï¼š")
        print("   1. åŸé…ç½®å·²å¤‡ä»½ï¼Œå¦‚éœ€å›æ»šè¯·ä½¿ç”¨å¤‡ä»½æ–‡ä»¶")
        print("   2. è¯·æ£€æŸ¥æ–°é…ç½®æ˜¯å¦æ­£ç¡®")
        print("   3. éƒ¨åˆ†ä¿¡æ¯æºå¯èƒ½éœ€è¦æ‰‹åŠ¨è°ƒæ•´é…ç½®")
        print("   4. ç¯å¢ƒå˜é‡é…ç½®è¯·ä½¿ç”¨ ${VAR_NAME} æ ¼å¼")

        return True

    def _convert_source(self, old_source: Dict[str, Any]) -> Dict[str, Any]:
        """è½¬æ¢å•ä¸ªä¿¡æ¯æºé…ç½®"""

        # æå–åŸºæœ¬ä¿¡æ¯
        source_id = old_source.get("id", "")
        source_name = old_source.get("name", "")
        source_type = old_source.get("type", "")
        source_category = old_source.get("category", "media")
        priority = old_source.get("priority", 5)
        enabled = old_source.get("enabled", True)

        # æå–æ—§çš„ config é…ç½®
        old_config = old_source.get("config", {})
        old_rate_limit = old_source.get("rate_limit", {})

        # æ ¹æ®ç±»å‹ç¡®å®š collector type
        if source_type == "blog" or source_type == "media" or source_type == "conference":
            if old_config.get("rss_url"):
                collector_type = "rss"
            else:
                collector_type = "scraper"
        elif source_type == "academic":
            if source_id.startswith("arxiv"):
                collector_type = "api"
            elif old_config.get("rss_url"):
                collector_type = "rss"
            else:
                collector_type = "scraper"
        elif source_type == "code":
            collector_type = "scraper"
        else:
            # é»˜è®¤ä½¿ç”¨ rss
            collector_type = "rss"

        # æ„å»ºæ–°é…ç½®
        new_source = {
            "metadata": {
                "id": source_id,
                "name": source_name,
                "description": f"{source_name} - {source_category}",
                "version": "1.0.0",
                "homepage": old_config.get("base_url"),
                "icon": self._get_icon_for_category(source_category),
                "tags": [source_type]
            },
            "categorization": {
                "category": source_category,
                "type": collector_type,
                "priority": priority,
                "language": "en"
            },
            "collector": self._build_collector_config(collector_type, old_config, source_id),
            "authentication": {
                "type": "none"
            },
            "rate_limit": {
                "requests_per_minute": old_rate_limit.get("requests_per_minute", 10)
            },
            "filters": {},
            "cache": {
                "enabled": True,
                "ttl_minutes": 60
            },
            "status": {
                "enabled": enabled,
                "stable": enabled and priority <= 3,
                "notes": "ç”±è¿ç§»å·¥å…·è‡ªåŠ¨è½¬æ¢"
            },
            "monitoring": {
                "log_level": "INFO",
                "alert_on_failure": False
            }
        }

        return new_source

    def _build_collector_config(self, collector_type: str, old_config: Dict[str, Any], source_id: str) -> Dict[str, Any]:
        """æ„å»ºé‡‡é›†å™¨é…ç½®"""

        if collector_type == "rss":
            return {
                "type": "rss",
                "rss_url": old_config.get("rss_url"),
                "base_url": old_config.get("base_url"),
                "update_frequency": "daily",
                "item_limit": old_config.get("max_results", 50)
            }

        elif collector_type == "api":
            # ä¸»è¦æ˜¯ arXiv
            return {
                "type": "api",
                "base_url": old_config.get("base_url", "http://export.arxiv.org/api/query"),
                "endpoint": "",
                "method": "GET",
                "params": {
                    "search_query": old_config.get("search_query"),
                    "max_results": old_config.get("max_results", 50),
                    "sortBy": old_config.get("sort_by", "submittedDate"),
                    "sortOrder": old_config.get("sort_order", "descending")
                },
                "response_format": "xml",
                "data_path": "feed.entries"
            }

        elif collector_type == "scraper":
            return {
                "type": "scraper",
                "url": old_config.get("base_url", old_config.get("news_url")),
                "base_url": old_config.get("base_url"),
                "selectors": {
                    "container": ".item, article, .post",
                    "title": ".title, h1, h2, h3",
                    "url": "a[href]",
                    "description": ".description, .excerpt, .summary",
                    "author": ".author, .byline",
                    "published_at": "time, .date, [datetime]"
                },
                "render_js": False
            }

        else:
            return {
                "type": "rss",
                "rss_url": old_config.get("rss_url"),
                "base_url": old_config.get("base_url")
            }

    def _get_icon_for_category(self, category: str) -> str:
        """æ ¹æ®åˆ†ç±»è·å–å›¾æ ‡"""
        icons = {
            "academic": "ğŸ“",
            "lab_blog": "ğŸ¢",
            "media": "ğŸ“°",
            "tools": "ğŸ› ï¸",
            "community": "ğŸ’¬",
            "newsletter": "ğŸ“§"
        }
        return icons.get(category, "ğŸ“„")

    def _show_statistics(self, sources: list):
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        print("ğŸ“Š è¿ç§»ç»Ÿè®¡ï¼š")
        print()

        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        category_count = {}
        type_count = {}
        enabled_count = 0

        for source in sources:
            cat = source["categorization"]["category"]
            typ = source["categorization"]["type"]
            status = source["status"]["enabled"]

            category_count[cat] = category_count.get(cat, 0) + 1
            type_count[typ] = type_count.get(typ, 0) + 1
            if status:
                enabled_count += 1

        print("   æŒ‰åˆ†ç±»ç»Ÿè®¡:")
        for cat, count in sorted(category_count.items()):
            print(f"     - {cat}: {count}")

        print()
        print("   æŒ‰é‡‡é›†æ–¹å¼ç»Ÿè®¡:")
        for typ, count in sorted(type_count.items()):
            print(f"     - {typ}: {count}")

        print()
        print(f"   æ€»è®¡: {len(sources)} ä¸ªä¿¡æ¯æºï¼Œ{enabled_count} ä¸ªå·²å¯ç”¨")


def main():
    """ä¸»å‡½æ•°"""
    migrator = SourceConfigMigrator("config")

    try:
        success = migrator.migrate()
        if success:
            print()
            print("âœ¨ è¿ç§»æˆåŠŸå®Œæˆï¼")
            return 0
        else:
            print()
            print("âŒ è¿ç§»å¤±è´¥")
            return 1
    except Exception as e:
        print(f"\nâŒ è¿ç§»å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
